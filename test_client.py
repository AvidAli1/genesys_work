import asyncio
import websockets
import json
import base64
import sounddevice as sd
import soundfile as sf
import threading
import time
import numpy as np
from pathlib import Path
import tempfile
import io
import queue
import signal
import sys
from concurrent.futures import ThreadPoolExecutor
import datetime
import httpx
class VoicebotSTTClient:
    def __init__(self, host="172.17.180.124", port=8000, tenant_id="d7acb015-1ce6-451d-b253-d7455070b4b4", user_id="f00ce248-5a04-41f5-97ca-828d24ea265a"):
        self.host = host
        self.port = port
        self.tenant_id = tenant_id
        self.user_id = user_id
        self.websocket_url = f"ws://{host}:{port}/ws/{tenant_id}/{user_id}"
        self.websocket = None
        self.recording = False
        self.streaming = False
        self.audio_queue = queue.Queue(maxsize=100)
        self.stop_event = threading.Event()
        
        # Audio settings optimized for backend processing
        self.sample_rate = 16000
        self.channels = 1
        self.chunk_duration_ms = 300
        self.chunk_size = int(self.sample_rate * self.chunk_duration_ms / 1000)
        
        # Buffer management
        self.audio_buffer = np.array([], dtype=np.int16)
        self.min_buffer_size = self.chunk_size * 10  # 1 second
        self.max_buffer_size = self.chunk_size * 30  # 3 seconds
        
        # CLI-style tracking
        self.chunk_counter = 0
        self.session_start_time = None
        
        # Thread pool for audio processing
        self.executor = ThreadPoolExecutor(max_workers=2)
        
        # Create transcription log file like CLI
        # with open("transcription.txt", "w", encoding="utf-8") as f:
        #     f.write(f"=== Transcription Session Started at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
        
        # # Create chat log file like CLI
        # with open("chat.txt", "w", encoding="utf-8") as f:
        #     f.write(f"=== Chat Session Started at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
        
        self.input_device = None  # Add this line

    def list_input_devices(self):
        print("\nAvailable input devices:")
        devices = sd.query_devices()
        input_devices = [d for d in devices if d['max_input_channels'] > 0]
        for idx, dev in enumerate(input_devices):
            print(f"{idx}: {dev['name']} (ID: {dev['index']})")
        return input_devices

    def select_input_device(self):
        input_devices = self.list_input_devices()
        if not input_devices:
            print("âŒ No input devices found.")
            return
        try:
            choice = int(input("Select input device by number (or press Enter for default): ") or -1)
            if 0 <= choice < len(input_devices):
                self.input_device = input_devices[choice]['index']
                dev_info = sd.query_devices(self.input_device)
                default_samplerate = int(dev_info['default_samplerate'])
                print(f"âœ… Selected device: {dev_info['name']}")
                print(f"   Default sample rate: {default_samplerate}")
                self.sample_rate = default_samplerate  # Set to device's default
            else:
                self.input_device = None
                print("â„¹ï¸ Using default input device.")
        except Exception as e:
            self.input_device = None
            print(f"â„¹ï¸ Using default input device. Error: {e}")

    async def connect(self):
        """Connect to the WebSocket"""
        try:
            print(f"ğŸ”— Connecting to {self.websocket_url}")
            self.websocket = await websockets.connect(self.websocket_url)
            print("âœ… Connected to WebSocket")
            self.session_start_time = time.time()
            return True
        except Exception as e:
            print(f"âŒ Connection failed: {e}")
            return False
    
    async def disconnect(self):
        """Disconnect from WebSocket"""
        if self.websocket:
            await self.websocket.close()
            print("ğŸ”Œ Disconnected from WebSocket")
    
    def audio_callback(self, indata, frames, time, status):
        """Audio callback - mimics CLI audio capture"""
        if status:
            print(f"âš ï¸ Audio callback status: {status}")
        
        if self.recording and not self.stop_event.is_set():
            mono_audio = indata[:, 0] if len(indata.shape) > 1 else indata.flatten()
            audio_int16 = (mono_audio * 32767).astype(np.int16)
            
            try:
                self.audio_queue.put_nowait(audio_int16)
            except queue.Full:
                print("âš ï¸ Audio queue full, dropping chunk")

    async def submit_text_query(self):
        query = input("Enter your text query: ").strip()
        self.api_url = f"http://{self.host}:{self.port}"
        self.token = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiZjAwY2UyNDgtNWEwNC00MWY1LTk3Y2EtODI4ZDI0ZWEyNjVhIiwidGVuYW50X2lkIjoiZDdhY2IwMTUtMWNlNi00NTFkLWIyNTMtZDc0NTUwNzBiNGI0IiwiaXNfYWRtaW4iOnRydWUsImV4cCI6MTc1NDI4OTgyN30.TEmmPc0siGvuhwRqGRx4OIVZVfMj_h0L6-SyEn3g6zk"
        if not query:
            print("âŒ Query cannot be empty")
            return
        url = f"{self.api_url}/query/submit"
        payload = {
            "tenant_id": self.tenant_id,
            "user_id": self.user_id,
            "query": query
        }
        headers = {"Authorization": f"Bearer {self.token}"} if self.token else {}
        async with httpx.AsyncClient() as client:
            try:
                response = await client.post(url, json=payload, headers=headers)
                print(f"âœ… Sent text-to-text request: {response.status_code}")
            except Exception as e:
                print(f"âŒ Error sending text-to-text request: {e}")
                return




    async def start_cli_style_pipeline(self, duration=None):
        """Start CLI-style continuous streaming using correct backend message types"""
        if not self.websocket:
            print("âŒ Not connected to WebSocket")
            return
        
        print("\nğŸ™ï¸ Starting CLI-style Audio Processing Pipeline")
        print("=" * 60)
        print("ğŸ”„ Audio Recorder â†’ STT â†’ RAG â†’ TTS Pipeline")
        print("ğŸ“ Output will match your CLI application format")
        if duration:
            print(f"â° Duration: {duration} seconds")
        else:
            print("â° Press Ctrl+C to stop")
        print("=" * 60)
        
        try:
            # Start continuous conversation mode (correct message type)
            await self.start_continuous_conversation()
            
            # Start recording and streaming
            await self.start_recording()
            streaming_task = asyncio.create_task(
                self.process_audio_chunks_continuously(duration)
            )
            await streaming_task
            
        except KeyboardInterrupt:
            print("\nğŸ›‘ Interrupted by user")
        except Exception as e:
            print(f"âŒ Error in streaming: {e}")
        finally:
            await self.stop_recording()
            await self.stop_continuous_conversation()
    
    async def start_continuous_conversation(self):
        """Start continuous conversation mode (correct message type)"""
        if not self.websocket:
            print("âŒ Not connected to WebSocket")
            return
        
        try:
            message = {
                "type": "start_continuous_conversation"
            }
            
            await self.websocket.send(json.dumps(message))
            print("âœ… Continuous conversation mode started")
            
        except Exception as e:
            print(f"âŒ Error starting continuous conversation: {e}")
    
    async def stop_continuous_conversation(self):
        """Stop continuous conversation mode"""
        if not self.websocket:
            return
        
        try:
            message = {
                "type": "stop_continuous_conversation"
            }
            
            await self.websocket.send(json.dumps(message))
            print("âœ… Continuous conversation mode stopped")
            
        except Exception as e:
            print(f"âŒ Error stopping continuous conversation: {e}")
    
    async def start_recording(self):
        """Start audio recording"""
        try:
            print("ğŸ¤ Starting audio capture...")
            print("ğŸ§ Listening...")  # Match CLI output
            
            self.recording = True
            self.streaming = True
            self.stop_event.clear()
            self.chunk_counter = 0
            
            # Clear buffers
            self.audio_buffer = np.array([], dtype=np.int16)
            while not self.audio_queue.empty():
                try:
                    self.audio_queue.get_nowait()
                except queue.Empty:
                    break
            
            # Start audio stream
            self.audio_stream = sd.InputStream(
                samplerate=self.sample_rate,
                channels=self.channels,
                callback=self.audio_callback,
                blocksize=self.chunk_size,
                dtype='float32',
                latency='low',
                device=self.input_device  # Add this line
            )
            self.audio_stream.start()
            print("âœ… Audio capture started")
            
        except Exception as e:
            print(f"âŒ Failed to start recording: {e}")
            self.recording = False
            self.streaming = False
    
    async def stop_recording(self):
        """Stop audio recording"""
        print("ğŸ›‘ Stopping audio capture...")
        self.recording = False
        self.streaming = False
        self.stop_event.set()
        
        if hasattr(self, 'audio_stream'):
            try:
                self.audio_stream.stop()
                self.audio_stream.close()
            except Exception as e:
                print(f"âš ï¸ Warning stopping audio stream: {e}")
        
        # Send any remaining audio
        if len(self.audio_buffer) > 0:
            await self.send_audio_chunk(self.audio_buffer, is_final=True)
            self.audio_buffer = np.array([], dtype=np.int16)
        
        print("âœ… Audio capture stopped")
    
    async def process_audio_chunks_continuously(self, duration=None):
        """Process audio chunks continuously"""
        start_time = time.time()
        last_send_time = start_time
        
        print("ğŸ“¡ Starting continuous audio processing...")
        
        while self.streaming and not self.stop_event.is_set():
            current_time = time.time()
            
            # Check duration limit
            if duration and (current_time - start_time) >= duration:
                print(f"\nâ° Duration limit reached ({duration}s)")
                break
            
            try:
                audio_chunk = self.audio_queue.get(timeout=0.05)
                self.audio_buffer = np.concatenate([self.audio_buffer, audio_chunk])
                
                # Send when we have enough audio (1-3 seconds like CLI chunks)
                should_send = (
                    len(self.audio_buffer) >= self.min_buffer_size and
                    (current_time - last_send_time) >= 1.0  # Send every 1 second
                ) or len(self.audio_buffer) >= self.max_buffer_size
                
                if should_send:
                    await self.send_audio_chunk(self.audio_buffer)
                    
                    # Clear buffer completely for next chunk
                    self.audio_buffer = np.array([], dtype=np.int16)
                    last_send_time = current_time
                    self.chunk_counter += 1
            
            except queue.Empty:
                await asyncio.sleep(0.01)
                continue
            except Exception as e:
                print(f"âŒ Error processing audio: {e}")
                break
        
        print(f"âœ… Audio processing complete")
    
    async def send_audio_chunk(self, audio_data, is_final=False):
        """Send audio chunk via WebSocket using correct message type"""
        try:
            audio_b64 = base64.b64encode(audio_data.tobytes()).decode('utf-8')
            
            # Use the correct message type that backend expects
            message = {
                "type": "continuous_audio_stream",
                "audio": audio_b64,
                "sample_rate": self.sample_rate,
                "channels": self.channels,
                "conversation_mode": True,  # Enable conversation mode for auto-response
                "auto_respond": True,       # Enable automatic responses
                "tts_language": "en",
                "voice": "en-US-JennyNeural",
                "timestamp": int(time.time() * 1000)
            }
            
            await self.websocket.send(json.dumps(message))
            
        except Exception as e:
            print(f"âŒ Error sending audio chunk: {e}")
    
    async def listen_for_responses(self):
        """Listen for responses from WebSocket - CLI-style output"""
        if not self.websocket:
            print("âŒ Not connected to WebSocket")
            return
        
        try:
            async for message in self.websocket:
                try:
                    data = json.loads(message)
                    try:
                        data = json.loads(message)
                        if isinstance(data, dict):
                            message_type = data.get("type", "unknown")
                        else:
                            print(f"âŒ Received non-dict message: {data}")
                            message_type = "unknown"
                    except Exception as e:
                        print(f"âŒ Error decoding message: {e}")
                        message_type = "unknown"
                    # Handle different message types with CLI-style formatting
                    if message_type == "transcription_result":
                        await self.handle_transcription_result(data)
                    
                        
                    elif message_type == "speech_detected":
                        await self.handle_speech_detected(data)
                        
                    elif message_type == "query_with_tts_result":
                        await self.handle_query_response(data)
                        
                    elif message_type == "query_with_tts_submitted":
                        # Query was submitted for processing
                        query_id = data.get('query_id', 'N/A')
                        print(f"ğŸ”„ [QUERY] Processing query {query_id[:8]}...")
                        
                    elif message_type == "audio_status":
                        await self.handle_audio_status(data)
                        
                    elif message_type == "audio_stream":
                        await self.handle_audio_stream(data)
                    elif message_type == "text_response":
                        print(f"ğŸ¤– Response: {data}")
                    elif message_type == "transcription_submitted":
                        # Transcription was submitted for processing
                        transcription_id = data.get('transcription_id', 'N/A')
                        print(f"ğŸ“ Transcribing at {datetime.datetime.now().strftime('%H:%M:%S')}")
                        
                    elif message_type == "continuous_conversation_started":
                        print("ğŸ”„ [SESSION] Continuous conversation started")
                        
                    elif message_type == "continuous_conversation_stopped":
                        print("ğŸ”„ [SESSION] Continuous conversation stopped")
                        
                    elif message_type == "error":
                        if data.type is str:
                            print(f"âŒ [ERROR] {data}")
                        else:
                            # Handle structured error messages
                            error_msg = data.get('message', 'Unknown error')
                            print(f"\nâŒ [ERROR] {error_msg}")
                        
                    elif message_type == "ping":
                        # Respond to ping
                        await self.websocket.send(json.dumps({"type": "pong"}))
                        
                    elif message_type == "pong":
                        print("ğŸ“ Pong received")
                        
                    else:
                        # Don't show unknown messages as errors, backend may send other types
                        pass
                        
                except json.JSONDecodeError:
                    print(f"âŒ Invalid JSON received: {message}")
                except Exception as e:
                    print(f"âŒ Error processing message: {e}")
                    
        except websockets.exceptions.ConnectionClosed:
            print("ğŸ”Œ WebSocket connection closed")
        except Exception as e:
            print(f"âŒ Error listening for responses: {e}")
    
    async def handle_transcription_result(self, data):
        """Handle transcription results - CLI format"""
        transcript = data.get('transcript', '').strip()
        chunk_id = data.get('chunk_id', 'N/A')
        confidence = data.get('confidence', 0.0)
        processing_time = data.get('processing_time', 0.0)
        
        if transcript:
            # Format like CLI output
            timestamp = datetime.datetime.now().strftime('%H:%M:%S')
            chunk_num = chunk_id.split('_')[-1] if '_' in chunk_id else chunk_id
            
            # Log to file like CLI
            # with open("transcription.txt", "a", encoding="utf-8") as f:
            #     f.write(f"\n[B{chunk_num[:3]}] {transcript}\n")
            
            print(f"â± Transcription took {processing_time:.2f} seconds")
            # with open("transcription.txt", "a", encoding="utf-8") as f:
            #     f.write(f"Transcription took {processing_time:.2f} seconds\n")
            
            # If this triggers a query, show the generating message
            if len(transcript.split()) > 1:  # Only for meaningful transcripts
                print(f"ğŸ§‘ Generating response for: {transcript}")
                # with open("chat.txt", "a", encoding="utf-8") as f:
                #     f.write(f"\n[{timestamp}] ğŸ§‘: {transcript}\n")
    
    async def handle_speech_detected(self, data):
        """Handle speech detection"""
        transcript = data.get('transcript', 'N/A')
        duration = data.get('duration', 0.0)
        # Only show if it's a meaningful transcript (backend shows these)
        if transcript and len(transcript.strip()) > 2:
            print(f"\nğŸ—£ï¸ [SPEECH] {transcript} ({duration:.1f}s)")
    
    async def handle_query_response(self, data):
        """Handle query response - CLI format"""
        response_text = data.get('response', 'N/A')
        query = data.get('query', 'N/A')
        timestamp = datetime.datetime.now().strftime('%H:%M:%S')
        
        # Display like CLI
        print(f"ğŸ¤– Response: {response_text}")
        # with open("chat.txt", "a", encoding="utf-8") as f:
        #     f.write(f"[{timestamp}] ğŸ¤–: {response_text}\n")
        
        # Show TTS processing like CLI
        print(f"ğŸ—£ Speaking: {response_text[:50]}{'...' if len(response_text) > 50 else ''}")
    
    async def handle_audio_status(self, data):
        """Handle TTS audio status"""
        status = data.get('status', 'N/A')
        task_id = data.get('task_id', 'N/A')
        
        if status == "ready":
            filename = data.get('data', {}).get('filename', 'N/A')
            print(f"ğŸ”Š [TTS] Ready: {filename}")
        elif status == "generating":
            print(f"ğŸ”„ [TTS] Generating...")
        elif status == "streaming":
            print(f"ğŸµ [TTS] Streaming audio...")
    
    async def handle_audio_stream(self, data):
        """Handle audio stream"""
        task_id = data.get('task_id', 'N/A')
        print(f"ğŸµ [AUDIO] Stream received (Task: {task_id[:8]})")
    
    async def send_audio_file(self, file_path):
        """Send an audio file for transcription"""
        if not self.websocket:
            print("âŒ Not connected to WebSocket")
            return
        
        try:
            data, sample_rate = sf.read(file_path)
            print(f"ğŸ“‚ Reading audio file: {file_path}")
            print(f"   Sample rate: {sample_rate}")
            print(f"   Channels: {data.shape[1] if len(data.shape) > 1 else 1}")
            print(f"   Duration: {len(data) / sample_rate:.2f}s")
            
            # Convert to mono if stereo
            if len(data.shape) > 1:
                data = np.mean(data, axis=1)
            
            # Resample if needed
            if sample_rate != self.sample_rate:
                print(f"   Resampling from {sample_rate} to {self.sample_rate}")
                try:
                    import scipy.signal
                    data = scipy.signal.resample(data, int(len(data) * self.sample_rate / sample_rate))
                except ImportError:
                    data = np.interp(
                        np.linspace(0, len(data), int(len(data) * self.sample_rate / sample_rate)),
                        np.arange(len(data)),
                        data
                    )
            
            # Convert to 16-bit integers
            data = (data * 32767).astype(np.int16)
            
            # Send complete file as audio stream
            audio_b64 = base64.b64encode(data.tobytes()).decode('utf-8')
            
            message = {
                "type": "audio_stream",
                "audio": audio_b64,
                "sample_rate": self.sample_rate,
                "channels": self.channels,
                "conversation_mode": False,  # Single file processing
                "final": True
            }
            
            await self.websocket.send(json.dumps(message))
            print("âœ… Audio file sent for transcription")
            
        except Exception as e:
            print(f"âŒ Error sending audio file: {e}")
    
    async def test_query_with_tts(self, query):
        """Test text query with TTS"""
        if not self.websocket:
            print("âŒ Not connected to WebSocket")
            return
        
        try:
            # Show like CLI
            timestamp = datetime.datetime.now().strftime('%H:%M:%S')
            print(f"ğŸ§‘ Generating response for: {query}")
            # with open("chat.txt", "a", encoding="utf-8") as f:
            #     f.write(f"\n[{timestamp}] ğŸ§‘: {query}\n")
            
            message = {
                "type": "query_with_tts",
                "message": query,
                "max_tokens": 500,
                "temperature": 0.7,
                "language": "en",
                "voice": "en-US-JennyNeural",
                "stream_audio": True
            }
            
            await self.websocket.send(json.dumps(message))
            print(f"âœ… Query sent: {query}")
            
        except Exception as e:
            print(f"âŒ Error sending query: {e}")
    
    async def send_ping(self):
        """Send ping to test connection"""
        if not self.websocket:
            print("âŒ Not connected to WebSocket")
            return
        
        try:
            message = {"type": "ping"}
            await self.websocket.send(json.dumps(message))
            print("ğŸ“ Ping sent")
        except Exception as e:
            print(f"âŒ Error sending ping: {e}")
    
    def cleanup(self):
        """Clean up resources"""
        self.stop_event.set()
        
        if hasattr(self, 'audio_stream'):
            try:
                self.audio_stream.stop()
                self.audio_stream.close()
            except Exception as e:
                print(f"âš ï¸ Warning during cleanup: {e}")
        
        if hasattr(self, 'executor'):
            self.executor.shutdown(wait=True)

# Signal handler for graceful shutdown
def signal_handler(signum, frame):
    print("\nğŸ›‘ Received interrupt signal, shutting down...")
    sys.exit(0)

async def main():
    signal.signal(signal.SIGINT, signal_handler)
    
    client = VoicebotSTTClient()
    
    try:
        if not await client.connect():
            return
        
        # Select input device
        client.select_input_device()
        
        # Start listening for responses in background
        listen_task = asyncio.create_task(client.listen_for_responses())
        
        print("\nğŸ¯Voicebot Client:")
        print("1. CLI-style Real-time Pipeline (unlimited)")
        print("2. Text Query")
        print("3. Exit")
        
        while True:
            try:
                choice = input("\nEnter your choice (1-8): ").strip()
                
                if choice == "1":
                    await client.start_cli_style_pipeline()
                elif choice == "2":
                    await client.submit_text_query()
                elif choice == "3":
                    print("ğŸ‘‹ Exiting...")
                    break
                else:
                    print("âŒ Invalid choice, please try again")
                    
            except KeyboardInterrupt:
                print("\nğŸ›‘ Interrupted by user")
                break
            except EOFError:
                print("\nğŸ›‘ Input stream ended")
                break
        
        listen_task.cancel()
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ Interrupted by user")
    except Exception as e:
        print(f"âŒ Error: {e}")
    finally:
        await client.disconnect()
        client.cleanup()

if __name__ == "__main__":
    print("ğŸ™ï¸ Style WebSocket Voice Client")
    print("=" * 60)

    print("ğŸ“ Transcribing at HH:MM:SS")
    print("â± Transcription took X.XX seconds")  
    print("ğŸ§‘ Generating response for: [query]")
    print("ğŸ¤– Response: [response]")
    print("ğŸ—£ Speaking: [text]")
    print("ğŸ“š Source citations")
    print("=" * 60)
    
    asyncio.run(main())